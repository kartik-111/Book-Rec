{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from scipy import stats\n",
    "from ast import literal_eval\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Collaborative Filtering\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "train_dat = pd.read_csv(os.getcwd() + '/train.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "meta_dat = pd.read_csv(os.getcwd() + '/books_metadata.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "meta_dat.dropna(subset=['item_id'], inplace=True)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "CountsOfReview = meta_dat[meta_dat['CountsOfReview'].notnull()]['CountsOfReview'].astype('int')\n",
    "Rating = meta_dat[meta_dat['Rating'].notnull()]['Rating'].astype('int')\n",
    "C = Rating.mean()\n",
    "C"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3.368927466020724"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "m = CountsOfReview.quantile(0.2)\n",
    "m"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "qualified = meta_dat[(meta_dat['CountsOfReview'] >= m) & (meta_dat['CountsOfReview'].notnull()) & (meta_dat['Rating'].notnull())][['Name', 'pagesNumber', 'Publisher', 'CountsOfReview', 'PublishYear', 'Language','Authors','Rating','item_id']]\n",
    "qualified['CountsOfReview'] = qualified['CountsOfReview'].astype('int')\n",
    "qualified['Rating'] = qualified['Rating'].astype('float')\n",
    "qualified['item_id'] = qualified['item_id'].astype('int')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def weighted_rating(x):\n",
    "    v = x['CountsOfReview']\n",
    "    R = x['Rating']\n",
    "    return (v/(v+m) * R) + (m/(m+v) * C)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "qualified['wr'] = qualified.apply(weighted_rating, axis=1)\n",
    "qualified = qualified.sort_values('wr', ascending=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "qualified['Name2'] = qualified['Name']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "qualified['Name'] = qualified['Name'].astype('string')\n",
    "qualified['Publisher'] = qualified['Publisher'].astype('string')\n",
    "qualified['Language'] = qualified['Language'].astype('string')\n",
    "qualified['Authors'] = qualified['Authors'].astype('string')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "qualified['Name'] = qualified['Name'].apply(lambda x: str.lower(x.replace(\" \", \"\")))\n",
    "qualified['Publisher'] = qualified['Publisher'].fillna('').apply(lambda x: str.lower(x.replace(\" \", \"\")))\n",
    "qualified['Language'] = qualified['Language'].fillna('').apply(lambda x: str.lower(x.replace(\" \", \"\")))\n",
    "qualified['Authors'] = qualified['Authors'].fillna('').apply(lambda x: str.lower(x.replace(\" \", \"\")))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "import string\n",
    "\n",
    "qualified['Name'] = qualified['Name'].fillna('').apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
    "qualified['Publisher'] = qualified['Publisher'].fillna('').apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
    "qualified['Language'] = qualified['Language'].fillna('').apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
    "qualified['Authors'] = qualified['Authors'].fillna('').apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "qualified['soup'] = qualified['Name'] + ' ' + qualified['Publisher'] + ' ' + qualified['Language'] + ' '+ qualified['Authors']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "qualified['soup']"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "14698      thecompletecalvinandhobbes andrewsmcmeelpublis...\n",
       "54922      markoftheliontrilogy tyndalehouse eng francine...\n",
       "6          harrypotterboxedsetbooks15harrypotter15 schola...\n",
       "32654                todamafalda edicionesdelaflor spa quino\n",
       "1593875    harrypotterseriesboxsetharrypotter17 arthurale...\n",
       "                                 ...                        \n",
       "372693     sexandthejapanesethesensualsideofjapan tuttlep...\n",
       "385718                mrsgod simonschusteraudio  peterstraub\n",
       "1006034               کافهیپریدریایی نشرچشمه per میتراالیاتی\n",
       "20383      citizengirl washingtonsquarepress enus emmamcl...\n",
       "642615       somersvsomers severnhousepublishers  julieellis\n",
       "Name: soup, Length: 37107, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "tf = TfidfVectorizer(analyzer='word',ngram_range=(1, 2),min_df=0, stop_words='english')\n",
    "tfidf_matrix = tf.fit_transform(qualified['soup'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "qualified = qualified.reset_index()\n",
    "book_titles = qualified['Name2']\n",
    "indices = pd.Series(qualified.index, index=qualified['Name2'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "def get_recommendations(book):\n",
    "    idx = indices[book]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:31]\n",
    "    book_indices = [i[0] for i in sim_scores]\n",
    "    return book_titles.iloc[book_indices]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "get_recommendations(\"One Night at the Call Center\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "36905                            The 3 Mistakes of My Life\n",
       "37098                         One Night at the Call Centre\n",
       "10551                       Black House (The Talisman, #2)\n",
       "22286             Taltos (Lives of The Mayfair Witches #3)\n",
       "25037             Taltos (Lives of the Mayfair Witches #3)\n",
       "26       J.R.R. Tolkien 4-Book Boxed Set: The Hobbit an...\n",
       "10541                 A Kiss of Shadows (Merry Gentry, #1)\n",
       "23841                                  Expedition To Earth\n",
       "27865                               The View from Serendip\n",
       "31987                    1984, Spring: A Choice of Futures\n",
       "7899       The Vampire Lestat (The Vampire Chronicles, #2)\n",
       "11444    Interview with the Vampire (The Vampire Chroni...\n",
       "16730    The Queen of the Damned (The Vampire Chronicle...\n",
       "18925                                        Cry to Heaven\n",
       "20383                     The Mummy (Ramses the Damned #1)\n",
       "23725      The Vampire Armand (The Vampire Chronicles, #6)\n",
       "31213                   Out of Egypt (Christ the Lord, #1)\n",
       "10201             J is for Judgment (Kinsey Millhone, #10)\n",
       "11991               K is for Killer (Kinsey Millhone, #11)\n",
       "14106               O is for Outlaw (Kinsey Millhone, #15)\n",
       "14638               G is for Gumshoe (Kinsey Millhone, #7)\n",
       "15756              H is for Homicide (Kinsey Millhone, #8)\n",
       "1253     The Best of H.P. Lovecraft: Bloodcurdling Tale...\n",
       "21776                    The Dream-Quest of Unknown Kadath\n",
       "13010          Rabbit Novels: Rabbit, Run and Rabbit Redux\n",
       "23007                    Rainbow's End (Richard Jury, #13)\n",
       "26233                   John Carter of Mars (Barsoom, #11)\n",
       "12812                   Shoulder the Sky (World War I, #2)\n",
       "12995           Seven Dials (Charlotte & Thomas Pitt, #23)\n",
       "15597       Long Spoon Lane (Charlotte & Thomas Pitt, #24)\n",
       "Name: Name2, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2.Collaborative Filtering\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "pip install scikit-surprise"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: scikit-surprise in /Users/k.c/opt/anaconda3/envs/py2/lib/python3.8/site-packages (1.1.3)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /Users/k.c/opt/anaconda3/envs/py2/lib/python3.8/site-packages (from scikit-surprise) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/k.c/opt/anaconda3/envs/py2/lib/python3.8/site-packages (from scikit-surprise) (1.24.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Users/k.c/opt/anaconda3/envs/py2/lib/python3.8/site-packages (from scikit-surprise) (1.10.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Users/k.c/opt/anaconda3/envs/py2/bin/python -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "from surprise import Reader, Dataset, SVD, KNNBasic,SVDpp\n",
    "from surprise.model_selection import cross_validate, train_test_split, GridSearchCV,KFold\n",
    "reader = Reader()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "user_data = Dataset.load_from_df(train_dat[['user_id', 'item_id', 'rating']], reader)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# this part has been commented out as it takes quite a long time to run\n",
    "'''\n",
    "param_grid = {'n_factors':[50,100,150],'lr_all':[0.005,0.01,0.1], 'reg_all': [0.005,0.01,0.1]}\n",
    "#kf = KFold(n_splits=5)\n",
    "grid_search = GridSearchCV(SVDpp,param_grid,measures=['rmse','mae'],cv=5)\n",
    "#trainset = user_data.build_full_trainset()\n",
    "grid_search.fit(user_data)\n",
    "'''"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"\\nparam_grid = {'n_factors':[50,100,150],'lr_all':[0.005,0.01,0.1], 'reg_all': [0.005,0.01,0.1]}\\n#kf = KFold(n_splits=5)\\ngrid_search = GridSearchCV(SVDpp,param_grid,measures=['rmse','mae'],cv=5)\\n#trainset = user_data.build_full_trainset()\\ngrid_search.fit(user_data)\\n\""
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "#best_params = grid_search.best_params"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "#best_params"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "algo = SVDpp(n_factors=50, lr_all=0.01,reg_all=0.1, reg_pu = 0.1, reg_qi = 0.1)\n",
    "# Run 5-fold cross-validation and print results. It may take a while!\n",
    "cross_validate(algo, user_data, measures=['RMSE', 'MAE'], cv=10, verbose=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVDpp on 10 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Fold 6  Fold 7  Fold 8  Fold 9  Fold 10 Mean    Std     \n",
      "RMSE (testset)    0.8796  0.8765  0.8831  0.8855  0.8833  0.8844  0.8890  0.8808  0.8831  0.8855  0.8831  0.0033  \n",
      "MAE (testset)     0.6969  0.6978  0.7014  0.7030  0.7007  0.7017  0.7065  0.6988  0.6989  0.7046  0.7010  0.0029  \n",
      "Fit time          97.73   98.75   99.32   100.70  100.62  101.42  99.47   100.44  101.14  102.11  100.17  1.26    \n",
      "Test time         3.89    3.83    3.76    3.60    3.75    3.62    3.68    3.65    3.62    3.71    3.71    0.09    \n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.87961197, 0.87651775, 0.88308696, 0.88552219, 0.88330817,\n",
       "        0.88442277, 0.88898057, 0.88080085, 0.88309033, 0.88551531]),\n",
       " 'test_mae': array([0.6969338 , 0.69784136, 0.701372  , 0.70302874, 0.70071503,\n",
       "        0.70171965, 0.7065301 , 0.69876405, 0.69889765, 0.70460416]),\n",
       " 'fit_time': (97.72826790809631,\n",
       "  98.75346493721008,\n",
       "  99.31804275512695,\n",
       "  100.6995439529419,\n",
       "  100.61679577827454,\n",
       "  101.41831493377686,\n",
       "  99.47268915176392,\n",
       "  100.43784499168396,\n",
       "  101.13804388046265,\n",
       "  102.10948705673218),\n",
       " 'test_time': (3.8909051418304443,\n",
       "  3.8285250663757324,\n",
       "  3.759868860244751,\n",
       "  3.596759080886841,\n",
       "  3.745759963989258,\n",
       "  3.6192309856414795,\n",
       "  3.6783809661865234,\n",
       "  3.6499099731445312,\n",
       "  3.6234359741210938,\n",
       "  3.7107839584350586)}"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "trainset = user_data.build_full_trainset()\n",
    "algo.fit(trainset)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVDpp at 0x177000d90>"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Hybrid Filter"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "#id_map = train_dat.merge(qualified[['Name2', 'item_id']], on='item_id').set_index('user_id')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "test_dat = pd.read_csv(os.getcwd() + '/test.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# Define a function to predict ratings using the content-based filtering method\n",
    "def predict_content_based(user_id, item_id):\n",
    "    matching_books = qualified[qualified['item_id'] == item_id]['Name2']\n",
    "    \n",
    "    if not matching_books.empty:\n",
    "        book = matching_books.iloc[0]\n",
    "        idx = indices[book]\n",
    "        sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "        sim_scores = sim_scores[1:31]\n",
    "        book_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "        # Calculate the weighted average of ratings of the top-30 similar books\n",
    "        similar_books = qualified.iloc[book_indices]\n",
    "        ratings_sum = sum(similar_books['CountsOfReview'] * similar_books['wr'])\n",
    "        count_sum = sum(similar_books['CountsOfReview'])\n",
    "        return ratings_sum / count_sum\n",
    "    else:\n",
    "        # Return the mean rating as a fallback if no matching book is found\n",
    "        return qualified['wr'].mean()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# Set the weight parameter for the hybrid approach (0 to 1)\n",
    "# Increase the weight to give more importance to collaborative filtering, and vice versa\n",
    "collab_weight = 1\n",
    "\n",
    "# Define a function to predict ratings using the hybrid approach\n",
    "def predict_hybrid(user_id, item_id):\n",
    "    content_based_rating = predict_content_based(user_id, item_id)\n",
    "    collaborative_prediction = algo.predict(user_id, item_id)\n",
    "    collaborative_rating = collaborative_prediction.est\n",
    "    return (1 - collab_weight) * content_based_rating + collab_weight * collaborative_rating\n",
    "\n",
    "\n",
    "# Apply the predict_hybrid function to the test_data DataFrame\n",
    "test_dat['hybrid_predicted_rating'] = test_dat.apply(lambda x: predict_hybrid(x['user_id'], x['item_id']), axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "#test_dat = test_dat.drop('rating', axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "test_dat = test_dat.rename(columns={'hybrid_predicted_rating':'rating'})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "kaggle_comp = test_dat[['ID','rating']]\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "kaggle_comp"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000</td>\n",
       "      <td>4.298543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>4.436031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100002</td>\n",
       "      <td>3.510039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100003</td>\n",
       "      <td>4.663597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100004</td>\n",
       "      <td>3.917604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56194</th>\n",
       "      <td>156194</td>\n",
       "      <td>3.726539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56195</th>\n",
       "      <td>156195</td>\n",
       "      <td>3.407031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56196</th>\n",
       "      <td>156196</td>\n",
       "      <td>4.377438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56197</th>\n",
       "      <td>156197</td>\n",
       "      <td>3.107648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56198</th>\n",
       "      <td>156198</td>\n",
       "      <td>3.404035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56199 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID    rating\n",
       "0      100000  4.298543\n",
       "1      100001  4.436031\n",
       "2      100002  3.510039\n",
       "3      100003  4.663597\n",
       "4      100004  3.917604\n",
       "...       ...       ...\n",
       "56194  156194  3.726539\n",
       "56195  156195  3.407031\n",
       "56196  156196  4.377438\n",
       "56197  156197  3.107648\n",
       "56198  156198  3.404035\n",
       "\n",
       "[56199 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "#kaggle_comp = kaggle_comp.drop('rating', axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "kaggle_comp['rating'] = kaggle_comp['rating'].round().astype(int)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "kaggle_comp.to_csv('kaggle_comp.csv', index = False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4.Matrix Factorization\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.1 Matrix Factorization without bias"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import implicit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics\n",
    "import scipy.sparse as sparse\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_dat,val_dat = train_test_split(train_dat, test_size=0.1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "def proc_col(col, train_col=None):\n",
    "    \"\"\"Encodes a pandas column with continous ids. \n",
    "    \"\"\"\n",
    "    if train_col is not None:\n",
    "        uniq = train_col.unique()\n",
    "    else:\n",
    "        uniq = col.unique()\n",
    "    name2idx = {o:i for i,o in enumerate(uniq)}\n",
    "    return name2idx, np.array([name2idx.get(x, -1) for x in col]), len(uniq)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "def encode_data(df, train=None):\n",
    "    \"\"\" Encodes rating data with continous user and item ids. \n",
    "    If train is provided, encodes df with the same encoding as train.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    for col_name in [\"user_id\", \"item_id\"]:\n",
    "        train_col = None\n",
    "        if train is not None:\n",
    "            train_col = train[col_name]\n",
    "        _,col,_ = proc_col(df[col_name], train_col)\n",
    "        df[col_name] = col\n",
    "        df = df[df[col_name] >= 0]\n",
    "    return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "train_df = encode_data(train_dat)\n",
    "val_df = encode_data(val_dat, train_dat)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "class MF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, emb_size=100):\n",
    "        super(MF, self).__init__()\n",
    "        self.user_emb = nn.Embedding(num_users, emb_size)\n",
    "        self.item_emb = nn.Embedding(num_items, emb_size)\n",
    "        self.user_emb.weight.data.uniform_(0, 0.05)\n",
    "        self.item_emb.weight.data.uniform_(0, 0.05)\n",
    "        \n",
    "    def forward(self, u, v):\n",
    "        u = self.user_emb(u)\n",
    "        v = self.item_emb(v)\n",
    "        return (u*v).sum(1)   "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "num_users = len(train_df.user_id.unique())\n",
    "num_items = len(train_df.item_id.unique())\n",
    "print(num_users, num_items)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4111 82876\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "mf_model = MF(num_users, num_items, emb_size=100)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "def train_epocs(model, epochs=10, lr=0.01, wd=0.0, unsqueeze=False):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    model.train()\n",
    "    for i in range(epochs):\n",
    "        users = torch.LongTensor(train_df.user_id.values)\n",
    "        items = torch.LongTensor(train_df.item_id.values)\n",
    "        ratings = torch.FloatTensor(train_df.rating.values)\n",
    "        if unsqueeze:\n",
    "            ratings = ratings.unsqueeze(1)\n",
    "        y_hat = model(users, items)\n",
    "        loss = F.mse_loss(y_hat, ratings)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(loss.item()) \n",
    "    return test_loss(model, unsqueeze)  # Return validation loss"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "def test_loss(model, unsqueeze=False):\n",
    "    model.eval()\n",
    "    users = torch.LongTensor(val_df.user_id.values)\n",
    "    items = torch.LongTensor(val_df.item_id.values)\n",
    "    ratings = torch.FloatTensor(val_df.rating.values)\n",
    "    if unsqueeze:\n",
    "        ratings = ratings.unsqueeze(1)\n",
    "    y_hat = model(users, items)\n",
    "    loss = F.mse_loss(y_hat, ratings)\n",
    "    print(\"test loss %.3f \" % loss.item())\n",
    "    return loss.item()  # Return test loss"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "train_epocs(mf_model, epochs=10, lr=0.1)\n",
    "train_epocs(mf_model, epochs=15, lr=0.01)\n",
    "train_epocs(mf_model, epochs=20, lr=0.01)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "14.689668655395508\n",
      "5.876476287841797\n",
      "1.7981023788452148\n",
      "4.586118221282959\n",
      "0.9701341390609741\n",
      "1.5058661699295044\n",
      "2.8874874114990234\n",
      "2.7863314151763916\n",
      "1.59674072265625\n",
      "0.7761574387550354\n",
      "test loss 1.790 \n",
      "1.3129481077194214\n",
      "0.7776018977165222\n",
      "0.5623425245285034\n",
      "0.5453683137893677\n",
      "0.6016244888305664\n",
      "0.650524377822876\n",
      "0.6631885766983032\n",
      "0.6428499221801758\n",
      "0.6050835251808167\n",
      "0.5659394860267639\n",
      "0.5362057089805603\n",
      "0.5196804404258728\n",
      "0.5142569541931152\n",
      "0.51470547914505\n",
      "0.5157244801521301\n",
      "test loss 0.900 \n",
      "0.5140005946159363\n",
      "0.49513471126556396\n",
      "0.4930191934108734\n",
      "0.4702049195766449\n",
      "0.46563073992729187\n",
      "0.4689072072505951\n",
      "0.46121951937675476\n",
      "0.44821521639823914\n",
      "0.4408150315284729\n",
      "0.43833717703819275\n",
      "0.4333813488483429\n",
      "0.42365914583206177\n",
      "0.41306930780410767\n",
      "0.40499448776245117\n",
      "0.3981654942035675\n",
      "0.38947856426239014\n",
      "0.378623366355896\n",
      "0.36782246828079224\n",
      "0.35833629965782166\n",
      "0.3491195738315582\n",
      "test loss 0.885 \n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8845368027687073"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "# encode the testing data\n",
    "df_test_emb = encode_data(test_dat, train_dat)\n",
    "\n",
    "# get the testing users and items\n",
    "users = torch.LongTensor(df_test_emb.user_id.values) # .cuda()\n",
    "items = torch.LongTensor(df_test_emb.item_id.values) # .cuda()\n",
    "\n",
    "# predict from model\n",
    "Y_mf = mf_model(users, items)\n",
    "\n",
    "\n",
    "min_max = MinMaxScaler(feature_range=(1, 5))\n",
    "res_scaled_mf = min_max.fit_transform(Y_mf.detach().numpy().reshape(-1, 1))[:,0]\n",
    "\n",
    "# Find the indices that are missing in the original test data\n",
    "missing_indices_mf = list(set(test_dat.index) - set(df_test_emb.index))\n",
    "\n",
    "# Fill missing values with mean of predictions\n",
    "mean_val_mf = np.mean(res_scaled_mf)\n",
    "for index in missing_indices_mf:\n",
    "    test_dat.loc[index, 'rating'] = mean_val_mf\n",
    "\n",
    "test_dat.loc[df_test_emb.index, 'rating'] = res_scaled_mf"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "test_dat"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>book_name</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000</td>\n",
       "      <td>0</td>\n",
       "      <td>406</td>\n",
       "      <td>Ready Player One (Ready Player One, #1)</td>\n",
       "      <td>3.051794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>0</td>\n",
       "      <td>4462</td>\n",
       "      <td>The Return of the Indian (The Indian in the Cu...</td>\n",
       "      <td>3.236578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100002</td>\n",
       "      <td>0</td>\n",
       "      <td>36746</td>\n",
       "      <td>Give and Take: A Revolutionary Approach to Suc...</td>\n",
       "      <td>2.372277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100003</td>\n",
       "      <td>0</td>\n",
       "      <td>5433</td>\n",
       "      <td>The Return of the King (The Lord of the Rings,...</td>\n",
       "      <td>3.262606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100004</td>\n",
       "      <td>0</td>\n",
       "      <td>1010</td>\n",
       "      <td>Mockingjay (The Hunger Games, #3)</td>\n",
       "      <td>2.861698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56194</th>\n",
       "      <td>156194</td>\n",
       "      <td>2965</td>\n",
       "      <td>36375</td>\n",
       "      <td>نکته‌های ویرایش</td>\n",
       "      <td>2.863262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56195</th>\n",
       "      <td>156195</td>\n",
       "      <td>2965</td>\n",
       "      <td>50982</td>\n",
       "      <td>از ترمه و تغزل</td>\n",
       "      <td>2.270313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56196</th>\n",
       "      <td>156196</td>\n",
       "      <td>2424</td>\n",
       "      <td>57260</td>\n",
       "      <td>The Seeing Stone (The Spiderwick Chronicles, #2)</td>\n",
       "      <td>3.134187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56197</th>\n",
       "      <td>156197</td>\n",
       "      <td>3077</td>\n",
       "      <td>30587</td>\n",
       "      <td>هیچ‌کس مثل تو مال این‌جا نیست</td>\n",
       "      <td>1.713181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56198</th>\n",
       "      <td>156198</td>\n",
       "      <td>2590</td>\n",
       "      <td>16844</td>\n",
       "      <td>J. D. Salinger's The Catcher in the Rye</td>\n",
       "      <td>2.273533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56199 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  user_id  item_id   \n",
       "0      100000        0      406  \\\n",
       "1      100001        0     4462   \n",
       "2      100002        0    36746   \n",
       "3      100003        0     5433   \n",
       "4      100004        0     1010   \n",
       "...       ...      ...      ...   \n",
       "56194  156194     2965    36375   \n",
       "56195  156195     2965    50982   \n",
       "56196  156196     2424    57260   \n",
       "56197  156197     3077    30587   \n",
       "56198  156198     2590    16844   \n",
       "\n",
       "                                               book_name    rating  \n",
       "0                Ready Player One (Ready Player One, #1)  3.051794  \n",
       "1      The Return of the Indian (The Indian in the Cu...  3.236578  \n",
       "2      Give and Take: A Revolutionary Approach to Suc...  2.372277  \n",
       "3      The Return of the King (The Lord of the Rings,...  3.262606  \n",
       "4                      Mockingjay (The Hunger Games, #3)  2.861698  \n",
       "...                                                  ...       ...  \n",
       "56194                                    نکته‌های ویرایش  2.863262  \n",
       "56195                                     از ترمه و تغزل  2.270313  \n",
       "56196   The Seeing Stone (The Spiderwick Chronicles, #2)  3.134187  \n",
       "56197                      هیچ‌کس مثل تو مال این‌جا نیست  1.713181  \n",
       "56198            J. D. Salinger's The Catcher in the Rye  2.273533  \n",
       "\n",
       "[56199 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "#test_dat = test_dat.drop('predicted_rating', axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "#test_dat = test_dat.drop('rating', axis=1)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "kaggle_mf = test_dat[['ID','rating']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "kaggle_mf"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000</td>\n",
       "      <td>3.051794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>3.236578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100002</td>\n",
       "      <td>2.372277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100003</td>\n",
       "      <td>3.262606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100004</td>\n",
       "      <td>2.861698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56194</th>\n",
       "      <td>156194</td>\n",
       "      <td>2.863262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56195</th>\n",
       "      <td>156195</td>\n",
       "      <td>2.270313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56196</th>\n",
       "      <td>156196</td>\n",
       "      <td>3.134187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56197</th>\n",
       "      <td>156197</td>\n",
       "      <td>1.713181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56198</th>\n",
       "      <td>156198</td>\n",
       "      <td>2.273533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56199 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID    rating\n",
       "0      100000  3.051794\n",
       "1      100001  3.236578\n",
       "2      100002  2.372277\n",
       "3      100003  3.262606\n",
       "4      100004  2.861698\n",
       "...       ...       ...\n",
       "56194  156194  2.863262\n",
       "56195  156195  2.270313\n",
       "56196  156196  3.134187\n",
       "56197  156197  1.713181\n",
       "56198  156198  2.273533\n",
       "\n",
       "[56199 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "kaggle_mf['rating'] = kaggle_mf['rating'].round().astype(int)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "#kaggle_mf.to_csv('kaggle_mf.csv', index = False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.2 MF with Bias"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "class MF_bias(nn.Module):\n",
    "    def __init__(self, num_users, num_items, emb_size=100):\n",
    "        super(MF_bias, self).__init__()\n",
    "        self.user_emb = nn.Embedding(num_users, emb_size)\n",
    "        self.user_bias = nn.Embedding(num_users, 1)\n",
    "        self.item_emb = nn.Embedding(num_items, emb_size)\n",
    "        self.item_bias = nn.Embedding(num_items, 1)\n",
    "        self.user_emb.weight.data.uniform_(0,0.05)\n",
    "        self.item_emb.weight.data.uniform_(0,0.05)\n",
    "        self.user_bias.weight.data.uniform_(-0.01,0.01)\n",
    "        self.item_bias.weight.data.uniform_(-0.01,0.01)\n",
    "        \n",
    "    def forward(self, u, v):\n",
    "        U = self.user_emb(u)\n",
    "        V = self.item_emb(v)\n",
    "        b_u = self.user_bias(u).squeeze()\n",
    "        b_v = self.item_bias(v).squeeze()\n",
    "        return (U*V).sum(1) +  b_u  + b_v"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "bias_model = MF_bias(num_users, num_items, emb_size=100)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "train_epocs(bias_model, epochs=10, lr=0.05, wd=1e-5)\n",
    "train_epocs(bias_model, epochs=10, lr=0.01, wd=1e-5)\n",
    "train_epocs(bias_model, epochs=10, lr=0.001, wd=1e-5)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "14.693587303161621\n",
      "10.770357131958008\n",
      "5.522363662719727\n",
      "1.3792730569839478\n",
      "1.7133736610412598\n",
      "3.413313150405884\n",
      "2.5406646728515625\n",
      "1.2144581079483032\n",
      "0.8843367099761963\n",
      "1.40267813205719\n",
      "test loss 2.312 \n",
      "2.075288772583008\n",
      "1.43146812915802\n",
      "0.982485294342041\n",
      "0.7458831667900085\n",
      "0.679992139339447\n",
      "0.6935455203056335\n",
      "0.7077181935310364\n",
      "0.6919205784797668\n",
      "0.6546518802642822\n",
      "0.6190200448036194\n",
      "test loss 0.915 \n",
      "0.6037217378616333\n",
      "0.5953822731971741\n",
      "0.5889489650726318\n",
      "0.5841619968414307\n",
      "0.5807275772094727\n",
      "0.5783566236495972\n",
      "0.5767918229103088\n",
      "0.5758203268051147\n",
      "0.5752724409103394\n",
      "0.575016438961029\n",
      "test loss 0.906 \n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9055701494216919"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "test_dat = test_dat.drop('rating', axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "Y_bias = bias_model(users, items)\n",
    "\n",
    "# Scaling between 1-5\n",
    "min_max = MinMaxScaler(feature_range=(1, 5))\n",
    "res_scaled_bias = min_max.fit_transform(Y_bias.detach().numpy().reshape(-1, 1))[:,0]\n",
    "\n",
    "# Find the indices that are missing in the original test data\n",
    "missing_indices_bias = list(set(test_dat.index) - set(df_test_emb.index))\n",
    "\n",
    "# Fill missing values with mean of predictions\n",
    "mean_val_bias = np.mean(res_scaled_bias)\n",
    "for index in missing_indices_bias:\n",
    "    test_dat.loc[index, 'rating'] = mean_val_bias\n",
    "\n",
    "\n",
    "test_dat.loc[df_test_emb.index, 'rating'] = res_scaled_bias\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "kaggle_bias = test_dat[['ID','rating']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "kaggle_bias['rating'] = kaggle_bias['rating'].round().astype(int)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "#kaggle_bias.to_csv('kaggle_bias.csv', index = False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. Feed Forward Neural Network\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "class CollabFNet(nn.Module):\n",
    "    def __init__(self, num_users, num_items, emb_size=100, n_hidden=10):\n",
    "        super(CollabFNet, self).__init__()\n",
    "        self.user_emb = nn.Embedding(num_users, emb_size)\n",
    "        self.item_emb = nn.Embedding(num_items, emb_size)\n",
    "        self.lin1 = nn.Linear(emb_size*2, n_hidden)\n",
    "        self.lin2 = nn.Linear(n_hidden, 1)\n",
    "        self.drop1 = nn.Dropout(0.1)\n",
    "        \n",
    "    def forward(self, u, v):\n",
    "        U = self.user_emb(u)\n",
    "        V = self.item_emb(v)\n",
    "        x = F.relu(torch.cat([U, V], dim=1))\n",
    "        x = self.drop1(x)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.lin2(x)\n",
    "        return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "net = CollabFNet(num_users, num_items, emb_size=500, n_hidden=10)\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# generated with help of ChatGPT\n",
    "train_users = torch.LongTensor(train_df.user_id.values)\n",
    "train_items = torch.LongTensor(train_df.item_id.values)\n",
    "train_ratings = torch.FloatTensor(train_df.rating.values).unsqueeze(1)  # adding an extra dimension\n",
    "\n",
    "\n",
    "for epoch in range(16): \n",
    "    net.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    prediction = net(train_users, train_items)\n",
    "    loss = loss_fn(prediction, train_ratings)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "   \n",
    "    \n",
    "    print(f\"Epoch {epoch}, Loss {loss.item()}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 0, Loss 14.456596374511719\n",
      "Epoch 1, Loss 12.329794883728027\n",
      "Epoch 2, Loss 10.022412300109863\n",
      "Epoch 3, Loss 7.879215240478516\n",
      "Epoch 4, Loss 6.004152774810791\n",
      "Epoch 5, Loss 4.423868656158447\n",
      "Epoch 6, Loss 3.150796890258789\n",
      "Epoch 7, Loss 2.1897385120391846\n",
      "Epoch 8, Loss 1.531598687171936\n",
      "Epoch 9, Loss 1.1589545011520386\n",
      "Epoch 10, Loss 1.0394032001495361\n",
      "Epoch 11, Loss 1.121405839920044\n",
      "Epoch 12, Loss 1.337876319885254\n",
      "Epoch 13, Loss 1.6195247173309326\n",
      "Epoch 14, Loss 1.8937078714370728\n",
      "Epoch 15, Loss 2.1085140705108643\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "net.eval() # set the model to evaluation mode\n",
    "Y_CFN = net(users, items)\n",
    "\n",
    "# Scaling between 0-1\n",
    "min_max = MinMaxScaler(feature_range=(1, 5))\n",
    "res_scaled_CFN = min_max.fit_transform(Y_CFN.detach().numpy())\n",
    "\n",
    "# Flatten to a 1D array\n",
    "res_scaled_CFN = res_scaled_CFN.flatten()\n",
    "\n",
    "# Find the indices that are missing in the original test data\n",
    "missing_indices_CFN = list(set(test_dat.index) - set(df_test_emb.index))\n",
    "\n",
    "# Fill missing values with mean of predictions\n",
    "mean_val_CFN = np.mean(res_scaled_CFN)\n",
    "for index in missing_indices_CFN:\n",
    "    test_dat.loc[index, 'predicted_rating'] = mean_val_CFN\n",
    "\n",
    "test_dat.loc[df_test_emb.index, 'predicted_rating'] = res_scaled_CFN"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "#test_dat = test_dat.drop('predicted_rating', axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "kaggle_NN = test_dat[['ID','predicted_rating']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "kaggle_NN['predicted_rating'] = kaggle_NN['predicted_rating'].round().astype(int)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "kaggle_NN = kaggle_NN.rename(columns={'predicted_rating':'rating'})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "#kaggle_NN.to_csv('kaggle_NN.csv', index = False)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}